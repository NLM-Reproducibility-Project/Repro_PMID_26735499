{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nlm_workshop:ovarian_cancer.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"PMvoi8wkMTRN","colab_type":"text"},"cell_type":"markdown","source":["Start up an AWS ubuntu instance and install docker. For this analysis, the following specs should be more than enough to run the bioinformatics pipeline.  \n","\n","\n","\n"]},{"metadata":{"id":"hW0cfA9O3wLL","colab_type":"code","colab":{}},"cell_type":"code","source":["docker build  .\n","docker push\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vmRAmzoWUjKS","colab_type":"text"},"cell_type":"markdown","source":["Pull the docker image."]},{"metadata":{"id":"L-nlB7MMUmTk","colab_type":"code","colab":{}},"cell_type":"code","source":["sudo docker pull jonessarae/nlm_workshop:seq_tools"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Hna6dcqIMjPB","colab_type":"text"},"cell_type":"markdown","source":["Download SRA files with sra_download.sh (check permissions) Already hardcoded with the SRA accession number. \n"]},{"metadata":{"id":"sQSE_d-CqEGa","colab_type":"code","colab":{}},"cell_type":"code","source":["./sra_download.sh"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tPVEnHZycoZX","colab_type":"text"},"cell_type":"markdown","source":["Run the docker container and add home directory to container. The rest of this notebook will be done within the container.\n","\n","---\n","\n"]},{"metadata":{"id":"sk-uOi4ActHC","colab_type":"code","colab":{}},"cell_type":"code","source":["sudo docker run -it -v ~:/mnt jonessarae/nlm_workshop:seq_tools"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yHjoEaCkNG23","colab_type":"text"},"cell_type":"markdown","source":["Convert SRA files into FASTQ files and split the files into read 1 and read 2. The command fastq-dump for SRA-toolkit does not use multi-threading. Better to find another package that can multi-thread. Can avoid splitting? In BWA can use -p option. How about others?"]},{"metadata":{"id":"7bSO4QDNSX8j","colab_type":"code","colab":{}},"cell_type":"code","source":["fastq-dump --split-files --origfmt --gzip SRR2989954.sra\n","gunzip SRR2989954_1.fastq.gz SRR2989954_1.fastq.gz\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Nlm-U-vhSex4","colab_type":"text"},"cell_type":"markdown","source":["Download reference genome hg19.2bit and tool twoBitToFa, convert 2bit file to fasta file, and index it with bwa. Use -t to add more cores for running bwa index faster."]},{"metadata":{"id":"q8JmtBeRSxyv","colab_type":"code","colab":{}},"cell_type":"code","source":["wget http://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/hg19.2bit\n","\n","rsync -aP rsync://hgdownload.soe.ucsc.edu/genome/admin/exe/linux.x86_64/twoBitToFa\n","chmod 744 twoBitToFa\n","./twoBitToFa hg19.2bit hg19.fa\n","\n","bwa index -a bwtsw hg19.fa "],"execution_count":0,"outputs":[]},{"metadata":{"id":"58RGKh8udpsc","colab_type":"text"},"cell_type":"markdown","source":["Download reference genome hg19 annotation file (GTF). There are two files to choose from. Not sure which to use. \n","https://www.gencodegenes.org/releases/19.html"]},{"metadata":{"id":"A6cmKWTXd-iX","colab_type":"code","colab":{}},"cell_type":"code","source":["wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_19/gencode.v19.annotation.gtf.gz\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"k6Jb8xJWeGQG","colab_type":"text"},"cell_type":"markdown","source":["Exome: Align paired reads to the reference genome and convert it to a bam file. With an AWS instance with 96 cores, this step took ~25 minutes (on file 54) with 96 threads. "]},{"metadata":{"id":"AQN6pQbdhJLf","colab_type":"code","colab":{}},"cell_type":"code","source":["bwa mem -t 8 ref/hg19.fa SRR2989954_1.fastq SRR2989954_2.fastq | samtools view -Sb - > SRR2989954.bam\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"14CL8QvARn4-","colab_type":"text"},"cell_type":"markdown","source":["Sort the bam files by genomic order.\n"]},{"metadata":{"id":"Zp4ln0KWR0BT","colab_type":"code","colab":{}},"cell_type":"code","source":["samtools sort -@ 4 SRR2989954.bam -o SRR2989954_sorted.bam\n","samtools sort -@ 8 SRR2989963.bam -o SRR2989963_sorted.bam"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jqRA7nhssArD","colab_type":"text"},"cell_type":"markdown","source":["RNA: Make genome indices that STAR requires. Always ensure read/write priveleges on files/folders. Check what read length should be: ReadLength-1. Does it matter if not 99? Change number of threads to 8. Mention spec requirements."]},{"metadata":{"id":"c1tst08ZsM4Q","colab_type":"code","colab":{}},"cell_type":"code","source":["mkdir star_indices\n","STAR --runThreadN 4 --runMode genomeGenerate --genomeDir star_indices --genomeFastaFiles ref/hg19.fa --sjdbGTFfile gtf//gencode.v19.annotation.gtf --sjdbOverhang 100\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Qa-NRMYphtMX","colab_type":"text"},"cell_type":"markdown","source":["RNA: Align paired reads to the reference genome. Don't forget to make a mapped_rna directory. "]},{"metadata":{"id":"ezEmrzoljLeg","colab_type":"code","colab":{}},"cell_type":"code","source":["mkdir mapped_rna\n","STAR --readFilesIn SRR2989969_1.fastq SRR2989969_2.fastq --runThreadN 8 --genomeDir star_indices --outFileNamePrefix mapped_rna/SRR29899692pass --genomeLoad NoSharedMemory --sjdbGTFfile gtf/gencode.v19.annotation.gtf --outSAMtype BAM SortedByCoordinate --twopassMode Basic\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"i0q3yTi0PIZH","colab_type":"text"},"cell_type":"markdown","source":["Exome: GATK4 from bioconda."]},{"metadata":{"id":"lAsRwf4XPYiE","colab_type":"code","colab":{}},"cell_type":"code","source":["java -Xmx4g -jar GenomeAnalysisTK.jar -I SRR2989954_sorted.bam -R ref/hg19.fa -T RealignerTargetCreator -o SRR2989954.intervals –known Mills_and_1000G_gold_standard.indels.hg19.vcf --read_filter MappingQualityZero \n","java -Xmx4g -jar GenomeAnalysisTK.jar -I SRR2989954_sorted.bam -R ref/hg19.fa -T IndelRealigner -targetIntervals sample.intervals -o SRR2989954_realign.bam -known Mills_and_1000G_gold_standard.indels.hg19.vcf --read_filter MappingQualityZero\n","\n","java -Xmx4g -jar GenomeAnalysisTK.jar -I SRR2989963_sorted.bam -R ref/hg19.fa -T RealignerTargetCreator -o SRR2989954.intervals –known Mills_and_1000G_gold_standard.indels.hg19.vcf --read_filter MappingQualityZero \n","java -Xmx4g -jar GenomeAnalysisTK.jar -I SRR2989963_sorted.bam -R ref/hg19.fa -T IndelRealigner -targetIntervals SRR2989963.intervals -o SRR2989963_realign.bam -known Mills_and_1000G_gold_standard.indels.hg19.vcf --read_filter MappingQualityZero\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TGVIpGV5WKuX","colab_type":"text"},"cell_type":"markdown","source":["Filter out reads that have mapping quality of < 20."]},{"metadata":{"id":"QbDmrPndWxAI","colab_type":"code","colab":{}},"cell_type":"code","source":["samtools view -b -q 20 SRR2989954_realign.bam > SRR2989954_m20.bam\n","samtools view -b -q 20 SRR2989963_realign.bam > SRR2989963_m20.bam\n","samtools view -b -q 20 mapped_rna/SRR29899692passAligned.sortedByCoord.out.bam > SRR2989969_m20.bam"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3e_6b7LodBGS","colab_type":"text"},"cell_type":"markdown","source":["Deduplicate files. We installed picard separately, but picard is also part of GATK4. "]},{"metadata":{"id":"TWBboYuDdyob","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","java -jar picard.jar MarkDuplicates I=SRR2989954_m20.bam O=SRR2989954_m20dedup.bam REMOVE_DUPLICATES=true METRICS_FILE=metrics.txt\n","java -jar picard.jar MarkDuplicates I=SRR2989963_m20.bam O=SRR2989963_m20dedup.bam REMOVE_DUPLICATES=true METRICS_FILE=metrics.txt\n","picard MarkDuplicates I=SRR2989969_m20.bam O=SRR2989969_m20dedup.bam REMOVE_DUPLICATES=true METRICS_FILE=metrics.txt\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Fj5gd-MXvu5C","colab_type":"text"},"cell_type":"markdown","source":["Generate VCF for multiple BAM files. Not sure how they run this except that it outputs vcf format. Not sure where the normal sample is in the VCF file. Assumed they combined all three with normal."]},{"metadata":{"id":"FJahBdNowEHT","colab_type":"code","colab":{}},"cell_type":"code","source":["samtools mpileup -f hg.19a SRR2989954_m20dedup.bam SRR2989963_m20dedup.bam SRR2989969_m20dedup.bam -v -o p1_ov.vcf"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HAPtqfyMuCXZ","colab_type":"text"},"cell_type":"markdown","source":["Calls variants from a mpileup dataset and produces a VCF.\n","\n"]},{"metadata":{"id":"iEiAxmMgvcdR","colab_type":"code","colab":{}},"cell_type":"code","source":["varscan mpileup2snp p1_ov.vcf --min-coverage 5 --min-reads2 0 --min-avg-qual 20 --min-var-freq 0 --output-vcf 13\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"om-gn8hzyYaF","colab_type":"text"},"cell_type":"markdown","source":["Run snpEff, a variant annotation and effect prediction tool. It annotates and predicts the effects of variants on genes. Not sure which version of the GRCh37 database was used. "]},{"metadata":{"id":"WTK7H6Q1ycv9","colab_type":"code","colab":{}},"cell_type":"code","source":["#snpEff databases | grep -i sapiens\n","snpEff download GRCh37.75\n","snpEff GRCh37.75 p1_ov.vcf > p1_ov.ann.vcf\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PPeS7AZWX9Af","colab_type":"text"},"cell_type":"markdown","source":["Count total reads and compare to supplementary figure 1."]},{"metadata":{"id":"JIYjf7xsYFk6","colab_type":"code","colab":{}},"cell_type":"code","source":["samtools flagstat <sample.bam>"],"execution_count":0,"outputs":[]},{"metadata":{"id":"r1nq_a5wc_v4","colab_type":"text"},"cell_type":"markdown","source":[""]}]}